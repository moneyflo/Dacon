{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "안녕하세요. '김상동구' 팀입니다.\n",
        "\n",
        "public 18등 (0.87619) , private 12등 (0.88049) 을 기록하였습니다.\n",
        "\n",
        "이번 대회의 베이스라인을 기반으로 colab에서 코드를 작성하였습니다.\n",
        "\n",
        "https://dacon.io/competitions/official/235894/codeshare/4722?page=1&dtype=recent"
      ],
      "metadata": {
        "id": "u9620hgW-ib4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 전처리\n",
        "\n",
        "이번 대회의 데이터셋 anomaly data의 양이 정상 데이터보다 개수가 훨씬 더 적었기 때문에 data augmentation을 사용해야 한다고 생각했습니다.\n",
        "\n",
        "augmentation 모듈 중 하나인 albumentations를 사용했는데, 다음 링크를 참조하여 사용했습니다.\n",
        "\n",
        "https://gaussian37.github.io/dl-pytorch-albumentation/"
      ],
      "metadata": {
        "id": "5peDHwPZ-7gE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 모델 선정\n",
        "\n",
        "모델은 efficientnet, wide resnet, inception, vgg 모델을 사용해서 앙상블을 해봤을 때 결과가 가장 좋았던 efficientnet_b3와 wide_resnet50_2의 조합을 사용했습니다.\n",
        "\n",
        "gpu power가 제한적이어서 많은 시도를 못해봤던 것이 아쉬웠습니다."
      ],
      "metadata": {
        "id": "VamUEcjx_hNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 훈련\n",
        "\n",
        "colab을 통해 코드를 돌리는 동안 런타임이 자주 끊기는 일이 발생하여서 매 epoch마다 모델을 저장하면서 training을 진행하였습니다.\n",
        "\n",
        "시간과 computing power가 부족하여 efficientnet_b3 모델은 115 epoch, \n",
        "wide_resnet50_2 모델은 78 epoch까지 훈련했습니다."
      ],
      "metadata": {
        "id": "oVsglemyKoKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 추론\n",
        "\n",
        "데이터의 크기가 크고 훈련할 anomaly data의 양이 적고 시간이 많이 걸려서 따로 validation set을 만들지 않고, 제출을 해서 결과를 확인한 후 parameter를 조정하였습니다.\n",
        "\n",
        "모델의 성능을 최대화하기 위해서 tta모듈 (test time augmentation)을 사용하여 추론하였습니다."
      ],
      "metadata": {
        "id": "Lya8SlotAutT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "SNKQJEMigofM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJFOcOknShHx",
        "outputId": "2ba3001d-96a5-4ffb-b4a1-274afb7a49f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python-headless==4.5.5.62"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B2B9SddKUSe",
        "outputId": "9cdab549-ffff-43f3-b2d4-319cdb531524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping opencv-python-headless as it is not installed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eligk4bTKVp7",
        "outputId": "b92e71d8-c785-4d0c-cec7-a4d62424fea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.21.6)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.5.2.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U albumentations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6kVslB2KXKd",
        "outputId": "4428f04a-95bb-4ba2-fa18-acc655c32e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n",
            "Collecting albumentations\n",
            "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Collecting qudida>=0.0.4\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.18.3)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.5.2.52)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (4.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
            "Installing collected packages: qudida, albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-1.1.0 qudida-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ttach"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f07QFlzQ9aGz",
        "outputId": "c864343e-74d6-4184-b8a9-fc92bc8fb26e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ttach\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Installing collected packages: ttach\n",
            "Successfully installed ttach-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ooaba2cWAdW"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import gc\n",
        "\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "\n",
        "import timm\n",
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import time\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import ttach as tta\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsnHU4e7WThU"
      },
      "outputs": [],
      "source": [
        "def seed_all(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "seed_all(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siIlSr1zWVcg"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Dacon/Dacon_CV\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset 불러오기"
      ],
      "metadata": {
        "id": "bKyX7PpBgylQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrP1ncvBWWe3"
      },
      "outputs": [],
      "source": [
        "train_png = sorted(glob('train/*.png'))\n",
        "test_png = sorted(glob('test/*.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSfN3BMRWXcT"
      },
      "outputs": [],
      "source": [
        "train_y = pd.read_csv(\"open/train_df.csv\")\n",
        "\n",
        "train_labels = train_y[\"label\"]\n",
        "\n",
        "label_unique = sorted(np.unique(train_labels))\n",
        "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
        "\n",
        "train_labels = [label_unique[k] for k in train_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcqZtvotXOmr"
      },
      "outputs": [],
      "source": [
        "def img_load(path):\n",
        "    img = cv2.imread(path)[:,:,::-1]\n",
        "    img = cv2.resize(img, (384, 384))\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awxgcaXCXRyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8290890f-9367-45b1-eb42-03314a8abf5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4277/4277 [12:48<00:00,  5.56it/s]\n",
            "100%|██████████| 2154/2154 [18:39<00:00,  1.92it/s]\n"
          ]
        }
      ],
      "source": [
        "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
        "test_imgs = [img_load(n) for n in tqdm(test_png)]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# albumentations을 이용한 Data Augmentation"
      ],
      "metadata": {
        "id": "lP1HKCwYg6Oa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOBHjAfuXToQ"
      },
      "outputs": [],
      "source": [
        "train_transform = A.Compose([\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1),\n",
        "        A.RandomGamma(gamma_limit=(90, 110)),\n",
        "        A.ShiftScaleRotate(scale_limit=0.1, rotate_limit=10),\n",
        "        A.Transpose(),\n",
        "        A.RandomRotate90(),\n",
        "        A.OneOf([A.NoOp(), A.MultiplicativeNoise(), A.GaussNoise(), A.ISONoise()]),\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.NoOp(p=0.8),\n",
        "                A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10),\n",
        "                A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10)\n",
        "            ],\n",
        "            p=0.2,\n",
        "        ),\n",
        "        A.OneOf([A.ElasticTransform(), A.GridDistortion(), A.NoOp()]),\n",
        "        ToTensorV2(),\n",
        "])\n",
        "\n",
        "\n",
        "test_transform = A.Compose([\n",
        "        ToTensorV2()\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configs"
      ],
      "metadata": {
        "id": "E4hk8g2B6P49"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR0O398VXd4k"
      },
      "outputs": [],
      "source": [
        "class Custom_dataset(Dataset):\n",
        "    def __init__(self, img_paths, labels, mode='train'):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode=mode\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.img_paths[idx]\n",
        "        if self.mode=='train':\n",
        "            img = train_transform(image=img)\n",
        "        \n",
        "        if self.mode=='test':\n",
        "            img = test_transform(image=img)\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        return img, label\n",
        "\n",
        "\n",
        "class Network_b3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network_b3, self).__init__()\n",
        "        self.model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=88)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Network_wrn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network_wrn, self).__init__()\n",
        "        self.model = timm.create_model('wide_resnet50_2', pretrained=True, num_classes=88)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHq5-Jw0XiH2"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 120\n",
        "\n",
        "# Train\n",
        "train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train')\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "# Test\n",
        "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## efficientnet_b3"
      ],
      "metadata": {
        "id": "pS-uPT8_DG0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score_function(real, pred):\n",
        "    score = f1_score(real, pred, average=\"macro\")\n",
        "    return score\n",
        "\n",
        "\n",
        "model_b3 = Network_b3().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model_b3.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "_FUfiOmcMpFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "cKUGAm4llWbu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C2iUIc3XkhA"
      },
      "outputs": [],
      "source": [
        "'''path = './weights/'\n",
        "if not os.path.isdir(path):\n",
        "    os.mkdir(path)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start=time.time()\n",
        "    train_loss = 0\n",
        "    train_pred=[]\n",
        "    train_y=[]\n",
        "    model_b3.train()\n",
        "    for batch in (train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x = torch.tensor(batch[0]['image'], dtype=torch.float32, device=device)\n",
        "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model_b3(x)\n",
        "        loss = criterion(pred, y)\n",
        "\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        train_loss += loss.item()/len(train_loader)\n",
        "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "        train_y += y.detach().cpu().numpy().tolist()\n",
        "\n",
        "    train_f1 = score_function(train_y, train_pred)\n",
        "    \n",
        "    TIME = time.time() - start\n",
        "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
        "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
        "\n",
        "    # 모델 저장\n",
        "    torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model_b3.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                \"scaler\": scaler.state_dict(),\n",
        "                'loss': loss,\n",
        "                }, f\"{path}/b3_model.pt\")'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## wide_resnet50_2 model"
      ],
      "metadata": {
        "id": "yUiZUb4RC8TO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_wrn = Network_wrn().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model_wrn.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPtwyS4PC6nv",
        "outputId": "a3e1be7c-c2d7-4fcb-846c-792c98ef28d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/wide_resnet50_racm-8234f177.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet50_racm-8234f177.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "05ZeVV_VDL_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''path = './weights/'\n",
        "if not os.path.isdir(path):\n",
        "    os.mkdir(path)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start=time.time()\n",
        "    train_loss = 0\n",
        "    train_pred=[]\n",
        "    train_y=[]\n",
        "    model_wrn.train()\n",
        "    for batch in (train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x = torch.tensor(batch[0]['image'], dtype=torch.float32, device=device)\n",
        "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model_wrn(x)\n",
        "        loss = criterion(pred, y)\n",
        "\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        train_loss += loss.item()/len(train_loader)\n",
        "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "        train_y += y.detach().cpu().numpy().tolist()\n",
        "\n",
        "    train_f1 = score_function(train_y, train_pred)\n",
        "    \n",
        "    TIME = time.time() - start\n",
        "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
        "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')\n",
        "\n",
        "    # 모델 저장\n",
        "    torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model_wrn.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                \"scaler\": scaler.state_dict(),\n",
        "                'loss': loss,\n",
        "                }, f\"{path}/wrn_model.pt\")'''"
      ],
      "metadata": {
        "id": "DMTHSmIZC7uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# efficientnet_b3 모델 불러오기\n",
        "\n",
        "loaded_model = torch.load('/content/drive/MyDrive/Dacon/Dacon_CV/weights/model_b3.pt')\n",
        "model_b3 = Network_b3().to(device)\n",
        "model_b3.load_state_dict(loaded_model['model_state_dict'])"
      ],
      "metadata": {
        "id": "Eoy-SMYKkGnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16dd2554-14d3-4de5-a056-646d031c1673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wide_resnet50_2 모델 불러오기\n",
        "\n",
        "loaded_model = torch.load('/content/drive/MyDrive/Dacon/Dacon_CV/weights/model_wrn.pt')\n",
        "model_wrn = Network_wrn().to(device)\n",
        "model_wrn.load_state_dict(loaded_model['model_state_dict'])"
      ],
      "metadata": {
        "id": "PjdxNaoYdt2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4deb64-4474-4d0c-e25d-9405ab50d709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TTA (test time augmentation)"
      ],
      "metadata": {
        "id": "-YziLWtUkeo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tta_transforms = tta.Compose(\n",
        "    [\n",
        "        tta.Rotate90(angles=[0, 90, 180, 270]),\n",
        "        tta.Multiply([0.9, 1])\n",
        "    ]\n",
        ")\n",
        "\n",
        "tta_model_b3 = tta.ClassificationTTAWrapper(model_b3, tta_transforms)\n",
        "tta_model_wrn = tta.ClassificationTTAWrapper(model_wrn, tta_transforms)"
      ],
      "metadata": {
        "id": "tzAAjEif06NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "t2bX4Jh0k0xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tta_model_b3.eval()\n",
        "tta_model_wrn.eval()\n",
        "f_pred = []\n",
        "\n",
        "with torch.no_grad  ():\n",
        "    for batch in (test_loader):\n",
        "        x = torch.tensor(batch[0]['image'], dtype = torch.float32, device = device)\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # ensemble\n",
        "            pred_b3 = tta_model_b3(x)\n",
        "            pred_wrn = tta_model_wrn(x)\n",
        "            pred = pred_b3 + pred_wrn\n",
        "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
      ],
      "metadata": {
        "id": "ub1O3Xuv0-ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submit"
      ],
      "metadata": {
        "id": "4DvTjd2D7u0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_decoder = {val:key for key, val in label_unique.items()}\n",
        "f_result = [label_decoder[result] for result in f_pred]\n",
        "\n",
        "submission = pd.read_csv(\"open/sample_submission.csv\")\n",
        "submission[\"label\"] = f_result\n",
        "\n",
        "submission"
      ],
      "metadata": {
        "id": "Unuq6pBx1Glw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(\"ensemble_b0_b3_inc_res_ver5.csv\", index = False)"
      ],
      "metadata": {
        "id": "KTI85eky9nLt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "[Private 12th, 0.88049] albumentation + Efficientnet/Resnet Ensemble + tta",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}